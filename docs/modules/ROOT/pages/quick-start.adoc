= Quick Start Guide
Ulli Schaechtle <u.schaechtle@gmail.com>

== Overview

This is a quickstart guide to help novice users use the GenSQL structure-learning codebase to build their own
models on tabular data and show how they can join these models with a large
population model (LPM). A large population model is a new class of foundational
model aimed at generating data about people.

The first step to get started is installing our software.

include::installation.adoc[]

== Build, Validation, and Submission Process

Structure learning for multivariate, heterogeneously-typed data is hard! 
The following describes how to build your project in a way that is supportable by the GenSQL team.
The process enables novice users to use GenSQL.structure-learning and contribute to the LPM. 
We ask that you iteratively test your model, increasing in size and complexity only after validating a smaller subset works. 
After each iteration we recommend sharing an artifact with the GenSQL team for validation and assistance. 
This ensures any problems that may occur are reproducible by the GenSQL team so that we can be maximally helpful.

=== Bug Reporting

If you run into something that you believe to be a bug while working your way through the tutorial, please 
follow the link:bug-reporting.adoc[instructions for triaging and reporting bugs]. 

== 1. Prepare and Document your Data File 

Copy your CSV file into GenSQL.structure_learning/data and rename it data.csv.

For more details on how to prepare your data see the link:data-preparation.adoc[Data Preparation] page.

=== Document your Data File
Before we begin modeling, we create a text file and an additional CSV file which will
describe your data. These two files are sent to the GenSQL team for review.

This helps the GenSQL team support users and ensures the data is suitable to be
joined into the LPM.

The text file records answers to the following checklist:

----
Describe the rows. In my CSV file `data/data.csv`, rows correspond to
    [ ] people
    [ ] geographic districts
    [ ] click events
    [ ] purchase events
    [ ] transaction events
    [ ] something else (if so, what?)

List the 10 most important columns below
    - ...
    [insert list here - use best guess; skip if your CSV has less than 10 columns]

List the 30 most important columns below
    - ...
    [insert list here - use best guess; skip if your CSV has less than 30 columns]

Which column could be described as "outcome" in the experimental sense?

    [insert column name here - use best guess]

Which columns predict this outcome?
    - ...
    [insert list here - use best guess]
----

The additional CSV file records the schema of your data, i.e. a table with five columns, where each row corresponds to a column:

. Name of column (without special characters)
. Short description (one or two sentences)
. Statistical type of the column: `numerical`, `nominal`, `count`. These types
are like data types but describe the underlying probability distribution (see
figure 1 https://papers.nips.cc/paper_files/paper/2016/file/46072631582fc240dd2674a7d063b040-Paper.pdf[here]). For index columns and other columns you want to keep around but don't want to model, write `ignore`.
. Count of missing values
. Count of unique values

=== When is this step complete?

Submit the checklist and the CSV file recording your schema to a member of the
GenSQL team. When they approve, you can move on to the next step.

== 2. Create a Small Test Data Set

First, create a version of your CSV file with ten columns only. Use the ten most important columns as per your answer above.

=== Configure the Pipeline

Open the file `params.yaml`. Ensure the fields specified are set as follows (leave the rest as-is):

[source, yaml]
----
sample_count: 10
sub_sample:
  N: 1000
nullify: # IF NEEDED
  # Entries added here will be treated as null. For example, to treat "NaN" and
  # "missing" as null uncomment the following two lines:
  # - NaN
  # - missing
schema:
  # Key/value pairs can be added here to explicitly override the inferred schema
  # for each column. The available types are as follows: numerical, nominal, and ignore.
  # For example, to force the "age" column to be treated as a
  # numerical uncomment the following line:
  # age: numerical
  # Apogee_km: numerical
  # Perigee_km: ignore
loom:
  extra_passes: 100
cgpm:
  minutes: 2
----

Explicitly write out all columns in the schema section instead of `age`, `Apogee_km` and `Perigee_km`.
See the link:pipeline-configuration.adoc[Pipeline Configuration] page for a detailed explanation of how to configure `params.yaml`.

== 3. Build the First Small Model
include::model-building.adoc[]

== 4. Validate the Small Model
include::quality-control.adoc[]

Does the synthetic data generated by the model (orange) look similar to the training data (black)?

== 5. Share the Model
include::model-sharing.adoc[]

=== When is this step complete?

A member of the GenSQL team will run `dvc pull` and check your result for any errors that are non-trivial to identify for 
novice users. When they approve, you can move on to the next step.

== 6. Run Baselines

include::baseline-comparison.adoc[]

=== When is this step complete?

A member from the GenSQL will run `dvc pull` and inspect `data/fidelity.png`.  When we beat the baselines, we can move to the next step.

== 7. Grow the Model

Set
https://github.com/OpenGen/GenSQL.structure-learning/blob/main/params.yaml#L10[this line] in `params.yaml` to 10000 and https://github.com/OpenGen/GenSQL.structure-learning/blob/main/params.yaml#L32[this line]
to 10 minutes.
----
dvc repro
----

Checkout `qc/app/qc-dashboard.html`. Does it look good?

Repeat step 3! How does `data/fidelity.png` look like?

Share the model and `data/fidelity.png` with us as described above.

=== When is this step complete?

A member from the GenSQL will run `dvc pull` and inspect `data/fidelity.png`.  When we beat the baselines, we can move to the next step.

== 8. Grow the Model Again

Change your CSV file to include the 30 most important columns instead of ten.
Set
https://github.com/OpenGen/GenSQL.structure-learning/blob/main/params.yaml#L32[this line]
to 60 minutes.
----
dvc repro
----

As before, checkout `qc/app/qc-dashboard.html`. Does it look good?

Repeat step 3! How does `data/fidelity.png` look like?

Share the model and `data/fidelity.png` with us as described above.

=== When is this step complete?

A member from the GenSQL will run `dvc pull` and inspect `data/fidelity.png`.  When we beat the baselines, we can move to the next step.

== 9. Model the Full Dataset

Repeat the process for the full dataset and share the model and `data/fidelity.png` with us as described above.

=== When is this step complete?

A member from the GenSQL will run `dvc pull` and inspect `data/fidelity.png`.  When we beat the baselines, we can move to the next step.

== 10. Smoke Test a Generative Join

TBD

== 11. Plot the Result a Generative Join

TBD
