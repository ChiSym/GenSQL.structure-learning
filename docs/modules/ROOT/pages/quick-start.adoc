= Quickstart
Ulli Schaechtle <u.schaechtle@gmail.com>

== Overview

This is a quickstart guide to help you use the IQL auto-modeling project to build your own
models on tabular data and query them. This guide starts with building a model from an example dataset.

== Installation

=== Dependencies

We rely on the Devenv package manager. Please find instructions to install it https://devenv.sh/getting-started/[here]. Devenv takes care of all our dependencies; currently confirmed to be working on Ubuntu and Mac.

Further, we require docker to be installed and to be runnable without `sudo`.
Installation instructions for Mac or Ubuntu are
https://docs.docker.com/engine/install/[here]. Then,
1. if on linux, run postinstall script: https://docs.docker.com/engine/install/linux-postinstall/
2. login using credentials sufficient for probcompâ€™s Docker org:
    1. if on linux run `docker login`
    2. if on mac, open the Docker app GUI and log in with credentials
3. Pull the Loom Docker image:
    1. Confirm you have access to view https://hub.docker.com/r/probcomp/inferenceql.loom
    2. Run `docker pull probcomp/inferenceql.loom`

=== Download Auto-modeling

Install from git
[source,bash]
----
git clone git@github.com:OpenIQL/inferenceql.auto-modeling.git InferenceQL
----

=== Start the Nix shell

To install modeling capabilities, go to the auto-modeling directory:
[source,bash]
----
cd InferenceQL
----
and enter a development shell that includes all the dependencies by running:
[source,bash]
----
devenv shell
----
WARNING: on macOS, this step can take up to an hour. The reason is that certain dependencies get compiled from scratch. It will only be slow once. The second time you run the `devenv shell` command, it will succeed instantaneously.

=== Running auto-modeling
Add a csv file:
[source,bash]
----
cp ~/foo/mydat.csv data/data.csv
----
Modify the `params.yaml` file as needed. And build default models:
[source,bash]
----
dvc repro
----

TIP: Check the automatically generated data schema in `data/schema.edn`. Does it look correct?
If not, see the section below on editing the schema generation.

Go to `qc/app/qc-dashboard.html` and open it with a web browser to check the quality.

You can improve the default models by further editing the `params.yaml` file.
See our xref:auto-modeling::auto-modeling.adoc[section on automated data
modeling].

TIP: Add columns you are particularly interested in to the `columns` section for quality control (see commented out example in the `params.yaml` file). That way, you can ensure that the model captures exactly what you care about.

If not, see the section below on editing the schema generation.

== Querying the model
There are different ways to query automatically built models from Python,
Clojure and JavaScript.
Checkout the https://github.com/InferenceQL/inferenceql.query[inferenceQL.query repository]
about how to query models and data.

== Publish your results

The auto-modeling pipeline prepares a directory for users to publish models and populations and supply the GitHub CLI tool to make it easy for users to contribute their results to a repository collecting analysis output.
[source,bash]
----
cd publish-analysis-output && gh auth login -w -h GitHub.com
----
This command will ask you to authenticate yourself with GitHub.
[source,bash]
----
gh pr create --base public --title "My analysis on [add dataset name and analysis goal here]" --body "Add more info here"
----
This command will fork our analyses repository, push your data and results to a branch, and open a pull request back to our repo. Users can use git to customize what get's published.

