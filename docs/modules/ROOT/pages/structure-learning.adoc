= Structure learning
Ulli Schaechtle <u.schaechtle@gmail.com>

== Overview

This guide will help you use the GenSQL structure-learning project to build your own models on tabular data. Once built, these models can be queried using a variety of interfaces. This guide starts with building a model from an example dataset. It then shows you how to build a model from a dataset you supply. And latter sections go into more detail about different backends for structure-learning and a number of other considerations.

== Installation

=== Dependencies

We rely on the Devenv package manager. Devenv takes care of all our dependencies; currently confirmed to be working on Ubuntu and Mac.

IMPORTANT: Updates to MacOS are known to cause issues with the Nix package manager that powers Devenv.

- Follow [this guide](https://devenv.sh/getting-started) steps 1 and 2 to install nix and devenv.

The minimum devenv  version is `1.0.0`.

Further, we require docker to be installed and to be runnable without `sudo`.
Installation instructions for Mac or Ubuntu are
https://docs.docker.com/engine/install/[here].

Then,

* if on linux, run postinstall script: https://docs.docker.com/engine/install/linux-postinstall/
* login using credentials sufficient for probcomp’s Docker org:
 ** if on linux run `docker login`
 ** if on mac, open the Docker app GUI and log in with credentials
* Pull the Loom Docker image:
 ** Confirm you have access to view https://hub.docker.com/r/probcomp/inferenceql.loom
 ** Run `docker pull probcomp/inferenceql.loom`

=== Download structure-learning

Install from git
[source,bash]
----
git clone git@github.com:OpenGen/GenSQL.structure-learning.git
----

=== Start the devenv shell

To install modeling capabilities, go to the structure-learning directory:
[source,bash]
----
cd GenSQL
----
and enter a development shell that includes all the dependencies by running:
[source,bash]
----
devenv shell
----
WARNING: on macOS, this step can take up to an hour. The reason is that certain dependencies get compiled from scratch. It will only be slow once. The second time you run the `devenv shell` command, it will succeed instantaneously.


== Building your first model

=== Add a dataset

Next, we will add the dataset we want to model.

We are going to be working with a dataset from a citizen science project on
satellites:

[source,bash]
----
cp test/satellites/data.csv data/data.csv
----


=== Run the structure-learning pipeline

GenSQL structure-learning is built around DVC (https://dvc.org/), a project that helps with version control of machine learning pipelines.

The steps for building a model are encoded as dvc pipelines (see `dvc.yaml`) All we have to do is run the pipeline and dvc takes care of the rest.

From the root structure-learning directory (`GenSQL`), we can run the following command to get a list of the pipeline stages and which files they will produce giving us an overview of the work that will be done to build the model.
[source,bash]
----
dvc stage list
----

Now to run all of the pipelines executing
[source,bash]
----
dvc repro
----
Run `dvc repro --help` to see different options of running the pipeline.


== Quality control plots

Before we use our model, how can we know it is any good?

structure-learning produces two quality control apps for comparing simulated data produced by the model and the original observed data.

You can find them in `qc/app` folder.

`qc-dashboard.html` shows comparisons between all combinations of columns, while `qc-splom.html` shows a scatter plot matrix of just numerical columns -- the latter is not so interesting here as none of the numerical columns are inferred automatically (though there are several numerical columns in the data, which one can add manually as in `test/satellites/params.yaml`).

These apps are fully contained in their respective html files, so they can be easily moved around or shared.

The premise of the qc-plots is following: if our model has truly learned the multi-variate distribution of the data then the marginal and pairwise-marginal distributions of simulations from the model should match those of the observed data. These qc-plots allow one to visually confirm this.

NOTE: The plots support a number of features including panning, zooming, cross-selection, and details on hover. There are also other options in the options menu. You can find more details in the QC section of this guide.

== Querying the model
There are different ways to query automatically built models from Python, Clojure and JavaScript.
Checkout the https://github.com/OpenGen/GenSQL.query[GenSQL.query repository] about how to query models and data.

== Configuring the pipeline

=== Data specifications/settings

There are a variety of settings in the `params.yaml` file in the structure-learning root dir. The following might need to be changed depending on your dataset.

==== schema

structure-learning tries to guess the statistical data types in your CSV. You can see
which statistical types are guessed by running `dvc repro -f guess-schema` and then opening `data/schema.edn`.

If you want to manually set the data types for one or more columns you can do that in `schema` section in `params.yaml`.

TIP: If a statistical type cannot be guessed with confidence, structure-learning chooses to ignore this column. You can add `default-stat-type: numerical` or `default-stat-type: nominal` if you prefer to define the stattypes of all columns that can't be guessed. This can save you some time when a lot of columns are ignored.

=== nullify

This setting allows you to specify which string values will be considered as
null values in your CSV. The system will treat strings as categories in a
categorical variable -- if you have, for example the string `NaN` encoding
missing data, you have to let the structure-learning system know.

=== Inference-related settings

There are a number of settings in `params.yaml` file that allow you to control the inference process. See the section below on the CGPM backend for more details on these settings.

=== QC options

See the comments in the `qc` section of the `params.yaml` file for details on the various settings available for QC plots.

== Sharing your models [[sharing]]

Sharing models works via https://dvc.org/doc/command-reference/remote#description[DVC remotes].
Remotes can be configured by editing the
https://github.com/OpenGen/GenSQL.structure-learning/blob/main/.dvc/config[.dvc/config file].

Users need to change the s3 bucket and sub-address in https://github.com/OpenGen/GenSQL.structure-learning/blob/main/.dvc/config#L5[this line]
to a bucket and directory that they have access to. Reach out to the team to get access to the buckets managed by the GenSQL team.

Once this is done, the process consists of pushing changes to GitHub and the remote:

1. Check out a new git branch by running `git checkout -b [branchname]`.
2. Ensure your pipeline is up-to-date by running `dvc repro`.
3. Check all raw data used in with DVC. For example, if the raw data consists of a single CSV and no pre-processing was added, you can run `dvc add data.csv` and follow the instructions in the terminal.
4. Commit local changes to the code, pipeline, and parameters. Ensure to always run `git add dvc.lock params.yaml dvc.yaml`.
5. Run `git commit` and add a message about what you changed.
6. Run `git push` (specifying upstream branch if needed).
7. Run `dvc push`.

NOTE: `dvc push` and `dvc pull` only work reliably when stages never get deleted manually from `dvc.yaml`. They *must* be deleted with `dvc remove [stage]`.

WARNING: Never push to the main branch on GitHub.

=== Downloading a model shared by someone else

1. Update your remote branches on Github by running `git fetch`. Then, check out an existing git branch by running `git checkout [branchname]`.
2. Confirm that you have access to the S3 bucket that serves as a DVC remote in `.dvc/config`.
3. Run `dvc pull`. The data and QC directories are now populated with what was checked into this branch.

== Reporting a bug or a problem

Bugs can be reported via our https://github.com/OpenGen/GenSQL.structure-learning/issues[issue tracker].
With Bayesian structure learning, bugs and problems can occur only when working with a specific model, schema, or dataset.
To ensure the GenSQL team can help you, please share a minimal version of our data and pipeline with us.

=== Report problems with models when the DVC pipeline runs end-to-end

If your DVC pipeline runs end-to-end but you are unhappy with model quality or
model behavior, please refer to the section about <<sharing>> above. Add a short description of the problem in the most recent commit message.

=== Report a crash of your DVC pipeline

If the DVC pipeline crashes when you run `dvc repro`, follow a four-step procedure.

First, create the  smallest possible configuration of the pipeline:
- Setting the https://github.com/OpenGen/GenSQL.structure-learning/blob/main/params.yaml#L3[sample_count] to 1.
- Set https://github.com/OpenGen/GenSQL.structure-learning/blob/main/params.yaml#L30[Loom inference steps] to 1.
- Set https://github.com/OpenGen/GenSQL.structure-learning/blob/main/params.yaml#L32-L33[Python inference steps] to 1.
- Sub-sample maximally 1000 rows by setting https://github.com/OpenGen/GenSQL.structure-learning/blob/main/params.yaml#L11[N here]

Second, create the smallest possible version of the data used for modeling that does  *not* crash.
To do this, edit the schema to ignore columns until the pipeline runs end-to-end with `dvc repro` by setting `column_foo: ignore`, `column_bar: ignore` etc.

Third, revisit the section on [[sharing]] and share the version that runs.
Ensure you don't have any remaining local changes in git (run `git status`).

Finally, make the minimal changes needed to reproduce the crash.
Record the changes you made into a text file. Run `git diff > change.txt`.
Commit the new file `change.txt` with git and push it to your branch.
If you provide the name of your branch the GenSQL team can run `git apply change.txt` to reproduce the crash.

== Model-building backends

GenSQL structure-learning supports a number of model-building backends. The previous sections on model building used the default CGPM backend. We will provide some more background on the CGPM backend here and also provide information on using alternatives.

=== Switching between backends

Each backend is encoded as a `yaml` file. When `dvc repro -f` is run, the yaml file for backend currently named `dvc.yaml` is run. To switch to a different backend, rename `dvc.yaml` to any temporary name. And rename the yaml file for the backend to you want to use to `dvc.yaml`.

=== CGPM

==== Key points
* Default backend
* Written in Python
* Robust
* DVC yaml filename: `dvc.yaml`

==== Settings
The following settings in `params.yaml` allow you to control the inferece process using the default backend, CGPM.

- `sample_count` — This lets you set the number of CrossCat models to learn, which together will comprise the ensemble.
- `cgpm > minutes` — The amount of time (minutes) to spend on inference. Use this setting or `cgpm > iterations` but not both.
- `cgpm > iterations` — The number CGPM interations to spend on inference. Use this setting or `cgpm > minutes` but not both.

==== Outputs

The key artifacts produced are as follows.

===== Individual CrossCat models

In `data/xcat/`, you can find multiple CrossCat models. Each one is a `.edn` file named `sample.0.edn`, `sample.1.edn`, etc. Any one of these individual CrossCat models can be used in an Observable notebook or in the GenSQL Viz spreadsheet app.

===== Ensemble of CrossCat models

`data/sppl/merged.json` is a sum-product network representation of all of the individual CrossCat models merged together forming an ensemble. This file can be used by GenSQL Query to start an GenSQL query server. The query server can then respond to sum-product queries from both an Observable notebook and the GenSQL Viz spreadsheet app. This is covered in a latter section.

===== Gen.clj models

Users can generate parametric https://github.com/probcomp/Gen.clj[Gen.clj] versions of the CrossCat models on the fly to test or edit. After a model was built and the DVC pipeline ran through, you can type the following and go to http://localhost:3000/[localhost:3000] in a web browser.
[source,bash]
----
clojure -X  gensql.structure-learning.code.webapp/start
----

=== Loom and CGPM

==== Key points
* Loom used to learn structure
* CGPM used to learn hyperparameters
* Loom is written in C with Python bindings
* Robust
* DVC yaml filename: `dvc-loom.yaml`

==== Setup
TODO: notes on getting the Docker image.

==== Settings
All the settings in `params.yaml` that apply to the CGPM backend also apply to the LOOM + CGPM backend. In addition, there are the following.

- `loom > extra_passes` — The number of extra inference passes to perform when learning structure.

==== Outputs
The outputs produced are the same as those produced by the CGPM backend. Please see the ouputs section for that backend.

==== Running additional inference

Sometimes, a user may wish to run additional CGPM inference without losing progress previously made. In order to run additional inference, users can run

[source,bash]
----
bin/update-inference
----

This will keep the previous result and spend another _n_ minutes with inference, where _n_ is specified in the `params.yaml` under `cgpm > minutes`.

==== Set qualitative dependence constraints

We can tell CrossCat to consider sets' of columns to be dependent or independent to improve modeling results.

This can be set in the `params.yaml` file. For dependence, edit the `cgpm` section, for example:

[source,yaml]
----
cgpm:
  minutes: 1
  dependence:
    foo:
      -bar
    baz:
      - quagga
----

While the CrossCat implementation in CGPM takes dependence constraints, doing so throws a not-implemented-error. Hence, we apply a workaround:
    - Supply a map from a target column name to a list of column names.
    - Each column in said list gets moved to the target column's view.

Similarly, we can ensure independence:

[source,yaml]
----
cgpm:
  minutes: 1
  independence:
    foo:
      - bar
      - baz
    quagga:
      - foo
----

Independence is un-directional. For two columns foo and bar, setting `foo: - bar` and `bar: - foo` has the identical effect.

=== Clojurecat

==== Key points
* Written in Clojure
* Usable from both the JVM and the browser (JS environments)
* Fewest requirements
* Experimental (there are know issues)
* DVC yaml filename: `dvc-clojurecat.yaml`

==== Settings
- `clojurecat > iterations` — This setting controls the amount of inference to perform.

==== Outputs

We can find our newly produced CrossCat model at `data/xcat/model.edn`.

=== Streaming Inference

==== Key points
* Experimental
* DVC yaml filename: `dvc-stream.yaml`

== References

TBD
