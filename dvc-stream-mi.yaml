# The following are stages related to computing MI in the dvc-stream.yaml pipeline. They can be used
# as an alternative to the default approach in dvc-stream.ymal of calculating dep-prob. These stages
# are meant to inserted into the dvc-stream.yaml pipeline and are not meant to be run independently.

stages:
  ### Stages related to converting CGPM models to SPNs (Needed for MI-related stages).

  sppl-import-checkpoints:
    desc: "Imports cgpm-model checkpoints as SPN checkpoints."
    cmd:
      - >-
        parallel jsonschema --instance {} schemas/cgpm.json
        :::: <(find data/cgpm/checkpoints/sample-* -type f)
      - >-
        parallel mkdir -p data/sppl/checkpoints/{}
        :::: <(find data/cgpm/checkpoints/sample-* -type d | cut -d/ -f4)
      - >-
        parallel $(bin/param parallel.flags)
        'python3 scripts/sppl_import_check.py
        --metadata {1}
        --data data/numericalized.csv
        --mapping-table data/mapping-table.edn
        --output data/sppl/checkpoints/{2}'
        :::: <(find data/cgpm/checkpoints/sample-* -type f)
        ::::+ <(find data/cgpm/checkpoints/sample-* -type f | cut -d/ -f4-5)
    params:
      - parallel.flags
    deps:
      - data/cgpm/checkpoints
      - data/ignored.csv
      - scripts/sppl_import_check.py
    outs:
      - data/sppl/checkpoints/

  ### Stages related to calculating mutual information between columns

  sppl-mi:
    desc: "Calculates MI from each SPN checkpoint."
    cmd:
      - >-
        parallel mkdir -p data/sppl/mi/checkpoints/{}
        :::: <(find data/sppl/checkpoints/sample-* -type d | cut -d/ -f4)
      - >-
        parallel $(bin/param parallel.flags)
        'python scripts/sppl_mi.py
        --model {1}
        --data data/ignored.csv
        --mapping-table data/mapping-table.edn
        --seed {2}
        --output data/sppl/mi/checkpoints/{3}'
        :::: <(find data/sppl/checkpoints/sample-* -type f)
        ::::+ <(find data/sppl/checkpoints/sample-* -type f | cut -d/ -f4 | grep -o -E '[0-9]+')
        ::::+ <(find data/sppl/checkpoints/sample-* -type f | cut -d/ -f4-5)
    params:
      - parallel.flags
      - mi.configs
    deps:
      - data/ignored.csv
      - data/sppl/checkpoints
      - data/mapping-table.edn
      - scripts/sppl_import_check.py
    outs:
      - data/sppl/mi/checkpoints/

  sppl-mi-merge:
    desc: "Merges MI outputs from SPN checkpoints corresponding each CrossCat sample."
    cmd:
      - mkdir -p data/sppl/mi/transitions/
      - >-
        parallel "jq --slurp '.' {1}/t-*.json > data/sppl/mi/transitions/{2}.json"
        :::: <(find data/sppl/mi/checkpoints/sample-* -type d)
        ::::+ <(find data/sppl/mi/checkpoints/sample-* -type d | cut -d/ -f5)
    deps:
      - data/sppl/mi/checkpoints/
    outs:
      - data/sppl/mi/transitions/

  sppl-mi-merge-phase-2:
    desc: >
      Concatenates MI outputs from all the CrossCat samples. Does not average MI accross all
      CrossCat samples. Instead, it leaves them in separate lists.
    cmd: >
      jq --slurp '.' data/sppl/mi/transitions/sample-*.json
      >  data/sppl/mi/transitions-merged-not-reduced.json
    deps:
      - data/sppl/mi/transitions/
    outs:
      - data/sppl/mi/transitions-merged-not-reduced.json

  sppl-mi-merge-phase-3:
    desc: >
      Averages MI values accross all CrossCat samples, such that there is a single set of MI values
      at each iteration.
    cmd: >-
      clojure -X inferenceql.auto-modeling.stream.mi/reduce
      :mi data/sppl/mi/transitions-merged-not-reduced.json
      > data/sppl/mi/transitions-merged.json
    deps:
      - data/sppl/mi/transitions-merged-not-reduced.json
    outs:
      - data/sppl/mi/transitions-merged.json
